{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "outputId": "1a04ac6f-257f-4638-fcf6-a20acabf7b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-17 06:35:56--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M   150MB/s    in 0.6s    \n",
      "\n",
      "2019-07-17 06:35:56 (150 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 06:35:57.284557 139775359944576 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Download the inception v3 weights\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights     = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CFsUlwdfs_wg",
    "outputId": "f28c08cd-5181-41e3-c447-4caebc2502b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        if(logs.get('acc')> 0.999):\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "outputId": "831ef05e-4199-4974-e8e9-308ba6534571"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0717 06:36:50.366946 139775359944576 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation = 'relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)       \n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation = 'sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "HrnL_IQ8knWA",
    "outputId": "4db12304-9f84-4db4-fee9-333ad9db4f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-17 06:37:05--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149574867 (143M) [application/zip]\n",
      "Saving to: ‘/tmp/horse-or-human.zip’\n",
      "\n",
      "/tmp/horse-or-human 100%[===================>] 142.65M   161MB/s    in 0.9s    \n",
      "\n",
      "2019-07-17 06:37:06 (161 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
      "\n",
      "--2019-07-17 06:37:06--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11480187 (11M) [application/zip]\n",
      "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
      "\n",
      "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-07-17 06:37:06 (73.6 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the Horse or Human dataset\n",
    "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
    "\n",
    "# Get the Horse or Human Validation dataset\n",
    "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '//tmp/horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = '//tmp/validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "O4s8HckqGlnb",
    "outputId": "3004b5ba-eca2-4558-d4fe-20250ff314a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale            = 1./255.,\n",
    "                                   rotation_range     = 40,\n",
    "                                   width_shift_range  = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range        = 0.2,\n",
    "                                   zoom_range         = 0.2,\n",
    "                                   horizontal_flip    = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size  = 20,\n",
    "                                                    class_mode  = 'binary', \n",
    "                                                    target_size = (150, 150))  \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zXlqTyXUqRZq",
    "outputId": "17aa4b2e-634e-421b-8c6a-57a2584a0ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "train_horses_dir = os.path.join(train_dir, 'horses')           # Directory with our training horse pictures\n",
    "train_humans_dir = os.path.join(train_dir, 'humans')           # Directory with our training humans pictures\n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans') # Directory with our validation humanas pictures\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "outputId": "12eac3aa-3086-487c-e371-db293aeaca68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 - 35s - loss: 0.1956 - acc: 0.9255 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "100/100 - 29s - loss: 0.0601 - acc: 0.9742 - val_loss: 0.0086 - val_acc: 0.9960\n",
      "Epoch 3/100\n",
      "100/100 - 29s - loss: 0.0290 - acc: 0.9894 - val_loss: 0.0382 - val_acc: 0.9889\n",
      "Epoch 4/100\n",
      "100/100 - 29s - loss: 0.0418 - acc: 0.9847 - val_loss: 0.1208 - val_acc: 0.9757\n",
      "Epoch 5/100\n",
      "100/100 - 28s - loss: 0.0479 - acc: 0.9838 - val_loss: 0.1431 - val_acc: 0.9757\n",
      "Epoch 6/100\n",
      "100/100 - 29s - loss: 0.0198 - acc: 0.9925 - val_loss: 0.0329 - val_acc: 0.9919\n",
      "Epoch 7/100\n",
      "100/100 - 28s - loss: 0.0399 - acc: 0.9883 - val_loss: 0.0757 - val_acc: 0.9929\n",
      "Epoch 8/100\n",
      "100/100 - 28s - loss: 0.0287 - acc: 0.9914 - val_loss: 0.0320 - val_acc: 0.9960\n",
      "Epoch 9/100\n",
      "100/100 - 29s - loss: 0.0376 - acc: 0.9899 - val_loss: 0.2148 - val_acc: 0.9727\n",
      "Epoch 10/100\n",
      "100/100 - 28s - loss: 0.0213 - acc: 0.9929 - val_loss: 0.0191 - val_acc: 0.9939\n",
      "Epoch 11/100\n",
      "100/100 - 29s - loss: 0.0212 - acc: 0.9924 - val_loss: 0.2307 - val_acc: 0.9798\n",
      "Epoch 12/100\n",
      "100/100 - 28s - loss: 0.0119 - acc: 0.9975 - val_loss: 0.3854 - val_acc: 0.9585\n",
      "Epoch 13/100\n",
      "100/100 - 28s - loss: 0.0314 - acc: 0.9914 - val_loss: 0.3610 - val_acc: 0.9565\n",
      "Epoch 14/100\n",
      "100/100 - 28s - loss: 0.0230 - acc: 0.9924 - val_loss: 0.3627 - val_acc: 0.9686\n",
      "Epoch 15/100\n",
      "100/100 - 29s - loss: 0.0407 - acc: 0.9904 - val_loss: 0.5917 - val_acc: 0.9484\n",
      "Epoch 16/100\n",
      "100/100 - 29s - loss: 0.0214 - acc: 0.9949 - val_loss: 0.1242 - val_acc: 0.9919\n",
      "Epoch 17/100\n",
      "100/100 - 28s - loss: 0.0336 - acc: 0.9919 - val_loss: 0.1610 - val_acc: 0.9889\n",
      "Epoch 18/100\n",
      "100/100 - 28s - loss: 0.0223 - acc: 0.9954 - val_loss: 0.7936 - val_acc: 0.9443\n",
      "Epoch 19/100\n",
      "100/100 - 29s - loss: 0.0222 - acc: 0.9955 - val_loss: 0.4552 - val_acc: 0.9676\n",
      "Epoch 20/100\n",
      "100/100 - 28s - loss: 0.0155 - acc: 0.9959 - val_loss: 0.4476 - val_acc: 0.9636\n",
      "Epoch 21/100\n",
      "100/100 - 28s - loss: 0.0155 - acc: 0.9934 - val_loss: 0.6939 - val_acc: 0.9534\n",
      "Epoch 22/100\n",
      "100/100 - 28s - loss: 0.0099 - acc: 0.9965 - val_loss: 0.5418 - val_acc: 0.9575\n",
      "Epoch 23/100\n",
      "100/100 - 28s - loss: 0.0126 - acc: 0.9965 - val_loss: 0.5317 - val_acc: 0.9575\n",
      "Epoch 24/100\n",
      "100/100 - 29s - loss: 0.0216 - acc: 0.9949 - val_loss: 0.3843 - val_acc: 0.9727\n",
      "Epoch 25/100\n",
      "100/100 - 28s - loss: 0.0238 - acc: 0.9949 - val_loss: 0.8467 - val_acc: 0.9494\n",
      "Epoch 26/100\n",
      "100/100 - 29s - loss: 0.0108 - acc: 0.9965 - val_loss: 0.7505 - val_acc: 0.9514\n",
      "Epoch 27/100\n",
      "100/100 - 28s - loss: 0.0213 - acc: 0.9929 - val_loss: 1.0162 - val_acc: 0.9352\n",
      "Epoch 28/100\n",
      "100/100 - 29s - loss: 0.0072 - acc: 0.9975 - val_loss: 0.6457 - val_acc: 0.9575\n",
      "Epoch 29/100\n",
      "100/100 - 29s - loss: 0.0221 - acc: 0.9949 - val_loss: 1.1171 - val_acc: 0.9342\n",
      "Epoch 30/100\n",
      "100/100 - 28s - loss: 0.0132 - acc: 0.9960 - val_loss: 1.4185 - val_acc: 0.9342\n",
      "Epoch 31/100\n",
      "100/100 - 28s - loss: 0.0112 - acc: 0.9959 - val_loss: 0.5595 - val_acc: 0.9686\n",
      "Epoch 32/100\n",
      "100/100 - 28s - loss: 0.0379 - acc: 0.9954 - val_loss: 1.0349 - val_acc: 0.9413\n",
      "Epoch 33/100\n",
      "100/100 - 28s - loss: 0.0154 - acc: 0.9949 - val_loss: 1.0418 - val_acc: 0.9453\n",
      "Epoch 34/100\n",
      "100/100 - 28s - loss: 0.0250 - acc: 0.9934 - val_loss: 1.1943 - val_acc: 0.9372\n",
      "Epoch 35/100\n",
      "100/100 - 28s - loss: 0.0223 - acc: 0.9955 - val_loss: 0.7021 - val_acc: 0.9555\n",
      "Epoch 36/100\n",
      "100/100 - 28s - loss: 0.0243 - acc: 0.9929 - val_loss: 0.8061 - val_acc: 0.9453\n",
      "Epoch 37/100\n",
      "100/100 - 28s - loss: 0.0094 - acc: 0.9975 - val_loss: 1.3965 - val_acc: 0.9332\n",
      "Epoch 38/100\n",
      "100/100 - 28s - loss: 0.0171 - acc: 0.9954 - val_loss: 1.7215 - val_acc: 0.9231\n",
      "Epoch 39/100\n",
      "100/100 - 28s - loss: 0.0079 - acc: 0.9985 - val_loss: 1.6925 - val_acc: 0.9271\n",
      "Epoch 40/100\n",
      "100/100 - 27s - loss: 0.0223 - acc: 0.9929 - val_loss: 1.3696 - val_acc: 0.9291\n",
      "Epoch 41/100\n",
      "100/100 - 30s - loss: 0.0094 - acc: 0.9965 - val_loss: 1.7933 - val_acc: 0.9251\n",
      "Epoch 42/100\n",
      "100/100 - 29s - loss: 0.0120 - acc: 0.9970 - val_loss: 1.6580 - val_acc: 0.9251\n",
      "Epoch 43/100\n",
      "100/100 - 28s - loss: 0.0182 - acc: 0.9970 - val_loss: 1.2790 - val_acc: 0.9332\n",
      "Epoch 44/100\n",
      "100/100 - 28s - loss: 0.0175 - acc: 0.9969 - val_loss: 1.5064 - val_acc: 0.9291\n",
      "Epoch 45/100\n",
      "100/100 - 28s - loss: 0.0174 - acc: 0.9950 - val_loss: 0.8467 - val_acc: 0.9555\n",
      "Epoch 46/100\n",
      "100/100 - 28s - loss: 0.0073 - acc: 0.9985 - val_loss: 1.2455 - val_acc: 0.9322\n",
      "Epoch 47/100\n",
      "100/100 - 28s - loss: 0.0245 - acc: 0.9964 - val_loss: 1.2925 - val_acc: 0.9332\n",
      "Epoch 48/100\n",
      "100/100 - 29s - loss: 0.0152 - acc: 0.9950 - val_loss: 1.0073 - val_acc: 0.9474\n",
      "Epoch 49/100\n",
      "100/100 - 28s - loss: 0.0027 - acc: 0.9985 - val_loss: 1.1305 - val_acc: 0.9423\n",
      "Epoch 50/100\n",
      "100/100 - 28s - loss: 0.0114 - acc: 0.9965 - val_loss: 0.8714 - val_acc: 0.9443\n",
      "Epoch 51/100\n",
      "100/100 - 29s - loss: 0.0103 - acc: 0.9965 - val_loss: 0.6356 - val_acc: 0.9595\n",
      "Epoch 52/100\n",
      "100/100 - 28s - loss: 0.0168 - acc: 0.9949 - val_loss: 0.8943 - val_acc: 0.9534\n",
      "Epoch 53/100\n",
      "100/100 - 28s - loss: 0.0130 - acc: 0.9959 - val_loss: 0.6650 - val_acc: 0.9605\n",
      "Epoch 54/100\n",
      "100/100 - 30s - loss: 0.0067 - acc: 0.9980 - val_loss: 1.1329 - val_acc: 0.9453\n",
      "Epoch 55/100\n",
      "100/100 - 29s - loss: 0.0124 - acc: 0.9954 - val_loss: 1.5284 - val_acc: 0.9352\n",
      "Epoch 56/100\n",
      "100/100 - 29s - loss: 0.0086 - acc: 0.9985 - val_loss: 0.8620 - val_acc: 0.9524\n",
      "Epoch 57/100\n",
      "100/100 - 28s - loss: 0.0104 - acc: 0.9975 - val_loss: 0.6553 - val_acc: 0.9615\n",
      "Epoch 58/100\n",
      "100/100 - 29s - loss: 0.0127 - acc: 0.9965 - val_loss: 0.7357 - val_acc: 0.9555\n",
      "Epoch 59/100\n",
      "100/100 - 28s - loss: 0.0079 - acc: 0.9970 - val_loss: 0.9317 - val_acc: 0.9423\n",
      "Epoch 60/100\n",
      "100/100 - 28s - loss: 0.0237 - acc: 0.9945 - val_loss: 0.5265 - val_acc: 0.9676\n",
      "Epoch 61/100\n",
      "100/100 - 28s - loss: 0.0172 - acc: 0.9969 - val_loss: 0.3607 - val_acc: 0.9808\n",
      "Epoch 62/100\n",
      "100/100 - 28s - loss: 0.0212 - acc: 0.9950 - val_loss: 0.8442 - val_acc: 0.9565\n",
      "Epoch 63/100\n",
      "100/100 - 28s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.5313 - val_acc: 0.9666\n",
      "Epoch 64/100\n",
      "100/100 - 28s - loss: 0.0147 - acc: 0.9965 - val_loss: 1.7274 - val_acc: 0.9291\n",
      "Epoch 65/100\n",
      "100/100 - 28s - loss: 0.0102 - acc: 0.9975 - val_loss: 0.7380 - val_acc: 0.9605\n",
      "Epoch 66/100\n",
      "100/100 - 27s - loss: 0.0100 - acc: 0.9965 - val_loss: 0.6205 - val_acc: 0.9656\n",
      "Epoch 67/100\n",
      "100/100 - 29s - loss: 0.0124 - acc: 0.9970 - val_loss: 0.7330 - val_acc: 0.9656\n",
      "Epoch 68/100\n",
      "100/100 - 30s - loss: 0.0062 - acc: 0.9975 - val_loss: 0.9979 - val_acc: 0.9474\n",
      "Epoch 69/100\n",
      "100/100 - 28s - loss: 0.0148 - acc: 0.9969 - val_loss: 1.3379 - val_acc: 0.9291\n",
      "Epoch 70/100\n",
      "100/100 - 29s - loss: 0.0089 - acc: 0.9980 - val_loss: 1.2692 - val_acc: 0.9362\n",
      "Epoch 71/100\n",
      "100/100 - 28s - loss: 0.0228 - acc: 0.9970 - val_loss: 1.8312 - val_acc: 0.9251\n",
      "Epoch 72/100\n",
      "100/100 - 27s - loss: 0.0174 - acc: 0.9970 - val_loss: 0.7740 - val_acc: 0.9575\n",
      "Epoch 73/100\n",
      "100/100 - 28s - loss: 0.0097 - acc: 0.9970 - val_loss: 0.8952 - val_acc: 0.9484\n",
      "Epoch 74/100\n",
      "100/100 - 28s - loss: 0.0071 - acc: 0.9985 - val_loss: 1.0159 - val_acc: 0.9443\n",
      "Epoch 75/100\n",
      "100/100 - 28s - loss: 0.0021 - acc: 0.9985 - val_loss: 0.6797 - val_acc: 0.9646\n",
      "Epoch 76/100\n",
      "100/100 - 28s - loss: 0.0192 - acc: 0.9964 - val_loss: 1.0276 - val_acc: 0.9504\n",
      "Epoch 77/100\n",
      "100/100 - 28s - loss: 0.0132 - acc: 0.9980 - val_loss: 1.1310 - val_acc: 0.9504\n",
      "Epoch 78/100\n",
      "100/100 - 28s - loss: 0.0063 - acc: 0.9970 - val_loss: 1.4034 - val_acc: 0.9393\n",
      "Epoch 79/100\n",
      "100/100 - 27s - loss: 0.0072 - acc: 0.9970 - val_loss: 1.3555 - val_acc: 0.9423\n",
      "Epoch 80/100\n",
      "100/100 - 29s - loss: 0.0041 - acc: 0.9980 - val_loss: 0.6537 - val_acc: 0.9646\n",
      "Epoch 81/100\n",
      "100/100 - 29s - loss: 0.0067 - acc: 0.9965 - val_loss: 1.1576 - val_acc: 0.9484\n",
      "Epoch 82/100\n",
      "100/100 - 29s - loss: 0.0119 - acc: 0.9970 - val_loss: 1.0132 - val_acc: 0.9504\n",
      "Epoch 83/100\n",
      "100/100 - 28s - loss: 0.0125 - acc: 0.9970 - val_loss: 1.0954 - val_acc: 0.9514\n",
      "Epoch 84/100\n",
      "100/100 - 28s - loss: 0.0143 - acc: 0.9980 - val_loss: 1.5418 - val_acc: 0.9453\n",
      "Epoch 85/100\n",
      "\n",
      "Reached 99.9% accuracy so cancelling training!\n",
      "100/100 - 29s - loss: 0.0076 - acc: 0.9995 - val_loss: 1.1170 - val_acc: 0.9443\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 99.9% accuracy\n",
    "# (It should take less than 100 epochs)\n",
    "\n",
    "callbacks = myCallback()\n",
    "history   = model.fit_generator(train_generator,\n",
    "                                validation_data  = validation_generator,\n",
    "                                steps_per_epoch  = 100,\n",
    "                                epochs           = 100,\n",
    "                                validation_steps = 50,\n",
    "                                verbose          = 2,\n",
    "                                callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL",
    "outputId": "84460462-a182-4424-e13d-f43e08cc2263"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAZDCGGMvsFgMIQQ/w+cp1rziNFUpQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc      = history.history['acc']\n",
    "val_acc  = history.history['val_acc']\n",
    "loss     = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc    , 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc = 0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNNw3 - Horses vs. Humans using Transfer Learning - WLH.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
